{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lhcb_calo_regression.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZQP2b_HDc2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as utils\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "sns.set()\n",
        "\n",
        "def one_hot(a, num_classes):\n",
        "    return np.squeeze(np.eye(num_classes)[a.reshape(-1)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM-ClPAODc21",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a629506b-b0f5-480a-dc9c-f07371b7c35b"
      },
      "source": [
        "device = torch.device('cuda:0')\n",
        "device"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0SHY0b_Dc29",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "ed6dedb7-d6af-4293-f112-28040d243c26"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ5sQFkjDc3B",
        "colab_type": "text"
      },
      "source": [
        "#### Data pathes\n",
        "\n",
        "If you are using Google colab left it as it is. \n",
        "\n",
        "Otherwise, if you are running notebook locally, change pathes accordinly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNVAryA0Dc3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_path = '/gdrive/My Drive/mlhep2019/data_train.npz'\n",
        "val_data_path = '/gdrive/My Drive/mlhep2019/data_val.npz'\n",
        "test_data_path = '/gdrive/My Drive/mlhep2019/data_test.npz'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXxfvbv8Dc3F",
        "colab_type": "text"
      },
      "source": [
        "# Loading data\n",
        "\n",
        "Data is stored in `.npz`-format which is a special filetype for persisting multiple NumPy arrays on disk. \n",
        "\n",
        "More info: https://docs.scipy.org/doc/numpy/reference/generated/numpy.lib.format.html#module-numpy.lib.format.\n",
        "\n",
        "File `dat_train.npz` contains four arrays: \n",
        "\n",
        "  * `EnergyDeposit` - images of calorimeters responses\n",
        "  * `ParticleMomentum` - $p_x, p_y, p_z$ of initial partice\n",
        "  * `ParticlePoint` - $x, y$ of initial particle\n",
        "  * `ParticlePDG` - particle type(either $e^-$ or $\\gamma$)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxvcWUEWDc3G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8e996ee-c074-4fe6-b5c5-15945e24945f"
      },
      "source": [
        "# open train dataset\n",
        "data_real = np.load(train_data_path, allow_pickle=True)\n",
        "print(list(data_real.keys()))\n",
        "\n",
        "# [data_size, 900]\n",
        "EnergyDeposit = data_real['EnergyDeposit']\n",
        "# reshaping it as [data_size, channels, img_size_x, img_size_y]\n",
        "# channels are needed for pytorch conv2d-layers\n",
        "EnergyDeposit = EnergyDeposit.reshape(-1, 1, 30, 30)\n",
        "\n",
        "# [data_size, 3]\n",
        "ParticleMomentum = data_real['ParticleMomentum']\n",
        "\n",
        "# [data_size, 2]\n",
        "ParticlePoint = data_real['ParticlePoint']\n",
        "\n",
        "# [data_size, 1]\n",
        "ParticlePDG = data_real['ParticlePDG']\n",
        "\n",
        "# augment training dataset\n",
        "# absolute momentum\n",
        "ParticleAbsMomentum2 = (np.power(data_real['ParticleMomentum'][:,0], 2) + \n",
        "                        np.power(data_real['ParticleMomentum'][:,1], 2) + \n",
        "                        np.power(data_real['ParticleMomentum'][:,2], 2))\n",
        "ParticleAbsMomentum = np.power(ParticleAbsMomentum2, 0.5)\n",
        "\n",
        "# particle energy\n",
        "m_e2 = np.ones_like(ParticlePDG) * (0.000511**2)\n",
        "ParticleEnergy_e = (data_real['ParticlePDG'] == 11) * ParticleAbsMomentum\n",
        "ParticleEnergy_gamma = (data_real['ParticlePDG'] == 22) * (np.sqrt(ParticleAbsMomentum2 + m_e2))\n",
        "ParticleEnergy = ParticleEnergy_gamma + ParticleEnergy_e\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['EnergyDeposit', 'ParticlePoint', 'ParticleMomentum', 'ParticlePDG']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPld3916Dc3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# not actully interested in p_z momentum\n",
        "ParticleMomentum = ParticleMomentum[:, :2]\n",
        "ParticlePoint = ParticlePoint[:, :2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB5GV24MDc3U",
        "colab_type": "text"
      },
      "source": [
        "# Loading it to pytorch `DataLoader`\n",
        "\n",
        "  1. Convert from `numpy`-array to Torch `tensors`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Gxha3yxDc3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EnergyDeposit = torch.tensor(EnergyDeposit).float()\n",
        "ParticleMomentum = torch.tensor(ParticleMomentum).float()\n",
        "ParticlePoint = torch.tensor(ParticlePoint).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YcClqhSLGVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AdditionalInfoP = torch.tensor(ParticleAbsMomentum).float()\n",
        "AdditionalInfoE = torch.tensor(ParticleEnergy).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cG-OJ6o3Dc3W",
        "colab_type": "text"
      },
      "source": [
        "  2. Convert three `tensors` to `TensorDataset`-format\n",
        "  3. Wrapping it with `DataLoader`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ6y8ppJDc3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 1024\n",
        "calo_dataset = utils.TensorDataset(EnergyDeposit, ParticleMomentum, ParticlePoint)\n",
        "calo_dataloader = torch.utils.data.DataLoader(calo_dataset, \n",
        "                                              batch_size=BATCH_SIZE, \n",
        "                                              pin_memory=True, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "773aqu09Dc3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Regressor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Regressor, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, 2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 2, stride=2)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 2)\n",
        "        self.conv4 = nn.Conv2d(64, 64, 2)\n",
        "                \n",
        "        self.fc1 = nn.Linear(1600, 512) \n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 32)\n",
        "        self.fc5 = nn.Linear(32, 16)\n",
        "        self.fc6 = nn.Linear(16, 2 + 2)\n",
        "        \n",
        "        self.dp1 = nn.Dropout(p=0.05)\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu((self.conv1(x)))\n",
        "        x = F.leaky_relu((self.conv2(x)))\n",
        "        x = F.leaky_relu((self.conv3(x)))\n",
        "        x = F.leaky_relu((self.conv4(x))) # 64, 5, 5\n",
        "        x = x.view(len(x), -1)\n",
        "\n",
        "        x = F.leaky_relu(self.fc1(x))\n",
        "        x = self.dp1(x)\n",
        "        x = F.leaky_relu(self.fc2(x))\n",
        "        x = F.leaky_relu(self.fc3(x))\n",
        "        x = F.leaky_relu(self.fc4(x))\n",
        "        x = F.leaky_relu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFYAS9FVDc3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regressor = Regressor().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNEjqJmNDc3b",
        "colab_type": "text"
      },
      "source": [
        "# Defining optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "YnYYpoNlDc3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 3e-4\n",
        "opt = optim.Adam(regressor.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x36DAf9rDc3c",
        "colab_type": "text"
      },
      "source": [
        "## Relative MSE that is used in competition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK4QnquLDc3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ParticleMomentum_mean, ParticlePoint_mean = ParticleMomentum.mean(dim=0), ParticlePoint.mean(dim=0)\n",
        "ParticleMomentum_ParticlePoint_mean = torch.cat([ParticleMomentum_mean, ParticlePoint_mean]).to(device)\n",
        "\n",
        "def metric_relative_mse(y_true, y_pred):\n",
        "    return ((y_true - y_pred).pow(2).mean(dim=0) / (y_true - ParticleMomentum_ParticlePoint_mean).pow(2).mean(dim=0)).sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79mdy7fRDc3i",
        "colab_type": "text"
      },
      "source": [
        "# Loss function\n",
        "\n",
        "In this example we are using `L1Loss`. \n",
        "\n",
        "But maybe it's better to stick to another loss?.. `MSE` or `log-cosh`?.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVwR2_7RDc3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss_fn = torch.nn.L1Loss().to(device)\n",
        "loss_fn = metric_relative_mse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXN-pf0oDc3j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RunningAverageMeter(object):\n",
        "    \"\"\"\n",
        "    Computes and stores the average and current value\n",
        "    \n",
        "    \"\"\"\n",
        "    def __init__(self, momentum=0.99):\n",
        "        self.momentum = momentum\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = None\n",
        "        self.avg = 0\n",
        "\n",
        "    def update(self, val):\n",
        "        if self.val is None:\n",
        "            self.avg = val\n",
        "        else:\n",
        "            self.avg = self.avg * self.momentum + val * (1 - self.momentum)\n",
        "        self.val = val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMnpQM06Dc3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_training(epochs=100):\n",
        "    losses = []\n",
        "    metrics = []\n",
        "    # init running average\n",
        "    loss_meter = RunningAverageMeter(momentum=0.99)\n",
        "    metric_meter = RunningAverageMeter(momentum=0.99)\n",
        "    # iterating over epochs...\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        # ...and over batches\n",
        "        for EnergyDeposit_b, ParticleMomentum_b, ParticlePoint_b in calo_dataloader:\n",
        "            # moving them to device(for example, cuda-device)\n",
        "            EnergyDeposit_b, ParticleMomentum_b, ParticlePoint_b = EnergyDeposit_b.to(device), \\\n",
        "                                                                   ParticleMomentum_b.to(device), \\\n",
        "                                                                   ParticlePoint_b.to(device)\n",
        "            \n",
        "            # predicting an array of size [batch_size, 4]\n",
        "            pred = regressor(EnergyDeposit_b)\n",
        "\n",
        "            # calc loss function\n",
        "            loss = loss_fn(pred, torch.cat([ParticleMomentum_b, ParticlePoint_b], dim=1))\n",
        "\n",
        "            # manually zeroing gradients from previous step\n",
        "            opt.zero_grad()\n",
        "            \n",
        "            # and calculating new gradients based on value of loss function\n",
        "            loss.backward()\n",
        "            \n",
        "            # updating weights\n",
        "            opt.step()\n",
        "            \n",
        "            # storing metrics for vizualization\n",
        "            loss_meter.update(loss.item())\n",
        "            metric_meter.update(metric_relative_mse(pred, torch.cat([ParticleMomentum_b, ParticlePoint_b], dim=1)).item())\n",
        "            losses.append(loss_meter.avg)\n",
        "            metrics.append(metric_meter.avg)\n",
        "    return losses, metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "3u50F_FPDc3m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "22ac6d91-f1f3-4a32-9c69-0812da275c87"
      },
      "source": [
        "# 10 epoch enought?\n",
        "losses, metrics = run_training(300)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 204/300 [06:04<02:52,  1.79s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-4b891498ab0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-a8ce50bbf23e>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;31m# predicting an array of size [batch_size, 4]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEnergyDeposit_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# calc loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-9eeaf077d000>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdp1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mweak_script\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m     \u001b[0;31m# type: (Tensor, float, bool) -> Tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKxn5LrJfTHf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "c85b6004-d444-461f-eadc-bb353c081545"
      },
      "source": [
        "# plot loss and our metric\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.plot(losses, label='Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "        \n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.plot(metrics, label='Metric')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-c64893eefeff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'losses' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x864 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTvqXqdaDc3n",
        "colab_type": "text"
      },
      "source": [
        "## Make predictions for validation set\n",
        "\n",
        "In `data_val.npz` and `data_test.npz` you only have one key: `EnergyDeposit`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyxjOhyKDc3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load validation data\n",
        "data_val = np.load(val_data_path, allow_pickle=True)\n",
        "EnergyDeposit_val = data_val['EnergyDeposit']\n",
        "EnergyDeposit_val = EnergyDeposit_val.reshape(-1, 1, 30, 30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSvN72UFDc3p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predicting [data_num, 4] array with px, py, x, y\n",
        "prediction_val = regressor.cpu()(torch.tensor(EnergyDeposit_val).float())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWYB7gQ4Dc3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# splitting ParticleMomentum and ParticlePoint in two arrays\n",
        "ParticleMomentum_val, ParticlePoint_val = prediction_val.detach().numpy()[:, :2], prediction_val.detach().numpy()[:, 2:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BzfCVM2Dc3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving predictions in .npz format\n",
        "np.savez_compressed('data_val_prediction.npz', \n",
        "                    ParticlePoint=ParticlePoint_val, \n",
        "                    ParticleMomentum=ParticleMomentum_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0rb26PJDc3v",
        "colab_type": "text"
      },
      "source": [
        "## Make predictions for test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwEK2cWjDc3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loading test dataset\n",
        "data_test = np.load(test_data_path, allow_pickle=True)\n",
        "EnergyDeposit_test = data_test['EnergyDeposit']\n",
        "EnergyDeposit_test = EnergyDeposit_test.reshape(-1, 1, 30, 30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WW25RNrPDc3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predicting [data_num, 4] array with px, py, x, y\n",
        "prediction_test = regressor.cpu()(torch.tensor(EnergyDeposit_test).float())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTDb27tnDc3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# splitting ParticleMomentum and ParticlePoint in two arrays\n",
        "ParticleMomentum_test, ParticlePoint_test = prediction_test.detach().numpy()[:, :2], prediction_test.detach().numpy()[:, 2:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DyakGLbDc3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving predictions in .npz format\n",
        "np.savez_compressed('data_test_prediction.npz', \n",
        "                    ParticlePoint=ParticlePoint_test, \n",
        "                    ParticleMomentum=ParticleMomentum_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5g7TFE2_Dc30",
        "colab_type": "text"
      },
      "source": [
        "## `zip-zip` files together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa4mMpjmDc31",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "abc1194c-cf3b-4252-e3d0-5eab97a7e42d"
      },
      "source": [
        "!zip solution.zip data_val_prediction.npz data_test_prediction.npz"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: data_val_prediction.npz (deflated 0%)\n",
            "  adding: data_test_prediction.npz (deflated 0%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uc9xo4SLDc32",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dcd700d7-dad6-497d-e72e-0ac4a9c913c2"
      },
      "source": [
        "from IPython.display import FileLink\n",
        "FileLink('./solution.zip')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<a href='./solution.zip' target='_blank'>./solution.zip</a><br>"
            ],
            "text/plain": [
              "/content/solution.zip"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgWVkv1_Dc33",
        "colab_type": "text"
      },
      "source": [
        "In Google Colab you might not be able to download you solution from browser. Then you can download it from left sidebar of Colab:\n",
        "\n",
        "![](https://github.com/philippgadow/mlhep2019_1_phase/blob/master/analysis/colab_download.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgEbIAPwDc33",
        "colab_type": "text"
      },
      "source": [
        "## Future steps:\n",
        "\n",
        "1. Tune arcitecture \n",
        "  * stack moar layers :)\n",
        "  * different types on nonlinearities, hyperparameters of `Conv2d`-layer, initializations, etc...\n",
        "  * dropout & other regularizations\n",
        "  \n",
        "  \n",
        "2. Play with optimization procedure\n",
        "  * train for more epochs\n",
        "  * maybe looking at train metricis is not the best way to prevent overfitting :)\n",
        "  * learning rate scheduler\n",
        "  * early stopping\n",
        "  * different types of loss functions: https://heartbeat.fritz.ai/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0\n",
        "  * SWA: https://pytorch.org/blog/stochastic-weight-averaging-in-pytorch/\n",
        "  \n",
        "  \n",
        "3. data augmentation\n",
        "  * rotate & shift images(do not forget to transform $p_x, p_y$, $x, y$ as well!)\n",
        "  * adding nose to images/target variables\n",
        "  \n",
        "  \n",
        "4. other trick\n",
        "  * train to predict $p_z$ and particle type: multi-task or/and transfer learning( http://rail.eecs.berkeley.edu/deeprlcourse-fa17/f17docs/lecture_15_multi_task_learning.pdf )\n",
        "  * normalization of input/output data: Box-Cox transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtywcAKXDc34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}