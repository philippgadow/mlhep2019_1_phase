{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lhcb_calo_regression.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZQP2b_HDc2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as utils\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "sns.set()\n",
        "\n",
        "def one_hot(a, num_classes):\n",
        "    return np.squeeze(np.eye(num_classes)[a.reshape(-1)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM-ClPAODc21",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e92868a-e61c-45eb-f75c-308f779e47dc"
      },
      "source": [
        "device = torch.device('cuda:0')\n",
        "device"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0SHY0b_Dc29",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "f8115dcc-867a-4739-ff09-2f84ea62f408"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ5sQFkjDc3B",
        "colab_type": "text"
      },
      "source": [
        "#### Data paths\n",
        "\n",
        "If you are using Google colab left it as it is. \n",
        "\n",
        "Otherwise, if you are running notebook locally, change pathes accordinly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNVAryA0Dc3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_path = '/gdrive/My Drive/mlhep2019/data_train.npz'\n",
        "val_data_path = '/gdrive/My Drive/mlhep2019/data_val.npz'\n",
        "test_data_path = '/gdrive/My Drive/mlhep2019/data_test.npz'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXxfvbv8Dc3F",
        "colab_type": "text"
      },
      "source": [
        "# Loading data\n",
        "\n",
        "Data is stored in `.npz`-format which is a special filetype for persisting multiple NumPy arrays on disk. \n",
        "\n",
        "More info: https://docs.scipy.org/doc/numpy/reference/generated/numpy.lib.format.html#module-numpy.lib.format.\n",
        "\n",
        "File `dat_train.npz` contains four arrays: \n",
        "\n",
        "  * `EnergyDeposit` - images of calorimeters responses\n",
        "  * `ParticleMomentum` - $p_x, p_y, p_z$ of initial partice\n",
        "  * `ParticlePoint` - $x, y$ of initial particle\n",
        "  * `ParticlePDG` - particle type(either $e^-$ or $\\gamma$)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxvcWUEWDc3G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f538b725-a848-4d2d-995d-5471d888970d"
      },
      "source": [
        "# open train dataset\n",
        "data_real = np.load(train_data_path, allow_pickle=True)\n",
        "print(list(data_real.keys()))\n",
        "\n",
        "# [data_size, 900]\n",
        "EnergyDeposit = data_real['EnergyDeposit']\n",
        "# reshaping it as [data_size, channels, img_size_x, img_size_y]\n",
        "# channels are needed for pytorch conv2d-layers\n",
        "EnergyDeposit = EnergyDeposit.reshape(-1, 1, 30, 30)\n",
        "\n",
        "# [data_size, 3]\n",
        "ParticleMomentum = data_real['ParticleMomentum']\n",
        "\n",
        "# [data_size, 2]\n",
        "ParticlePoint = data_real['ParticlePoint']\n",
        "\n",
        "# [data_size, 1]\n",
        "ParticlePDG = data_real['ParticlePDG']\n",
        "\n",
        "# augment training dataset\n",
        "# absolute momentum\n",
        "ParticleAbsMomentum2 = (np.power(data_real['ParticleMomentum'][:,0], 2) + \n",
        "                        np.power(data_real['ParticleMomentum'][:,1], 2) + \n",
        "                        np.power(data_real['ParticleMomentum'][:,2], 2))\n",
        "ParticleAbsMomentum = np.power(ParticleAbsMomentum2, 0.5)\n",
        "\n",
        "# particle energy - not super useful though, since electrons are relativistic\n",
        "m_e2 = np.ones_like(ParticlePDG) * (0.000000511**2)\n",
        "ParticleEnergy_e = (data_real['ParticlePDG'] == 11) * ParticleAbsMomentum\n",
        "ParticleEnergy_gamma = (data_real['ParticlePDG'] == 22) * \\\n",
        "                       (np.sqrt(ParticleAbsMomentum2 + m_e2))\n",
        "ParticleEnergy = ParticleEnergy_gamma + ParticleEnergy_e\n",
        "\n",
        "# theta\n",
        "ParticleMomentumZ = data_real['ParticleMomentum'][:,2]\n",
        "pt = np.power((np.power(data_real['ParticleMomentum'][:,0], 2) + \\\n",
        "               np.power(data_real['ParticleMomentum'][:,1], 2)), 0.5)\n",
        "theta = np.arctan(pt / ParticleMomentumZ)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['EnergyDeposit', 'ParticlePoint', 'ParticleMomentum', 'ParticlePDG']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPld3916Dc3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# not interested in pz\n",
        "ParticleMomentum = ParticleMomentum[:, :2]\n",
        "ParticlePoint = ParticlePoint[:, :2]\n",
        "\n",
        "# additional information: pdg ID with uncertainty and energy\n",
        "AdditionalInfo = np.column_stack((theta, ParticleEnergy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB5GV24MDc3U",
        "colab_type": "text"
      },
      "source": [
        "# Loading it to pytorch `DataLoader`\n",
        "\n",
        "  1. Convert from `numpy`-array to Torch `tensors`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Gxha3yxDc3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EnergyDeposit = torch.tensor(EnergyDeposit).float()\n",
        "ParticleMomentum = torch.tensor(ParticleMomentum).float()\n",
        "ParticlePoint = torch.tensor(ParticlePoint).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YcClqhSLGVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AdditionalInfo = torch.tensor(np.array(AdditionalInfo)).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cG-OJ6o3Dc3W",
        "colab_type": "text"
      },
      "source": [
        "  2. Convert three `tensors` to `TensorDataset`-format\n",
        "  3. Wrapping it with `DataLoader`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ6y8ppJDc3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 1024\n",
        "calo_dataset = utils.TensorDataset(EnergyDeposit, ParticleMomentum,\n",
        "                                   ParticlePoint, AdditionalInfo)\n",
        "calo_dataloader = torch.utils.data.DataLoader(calo_dataset, \n",
        "                                              batch_size=BATCH_SIZE, \n",
        "                                              pin_memory=True, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "773aqu09Dc3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Regressor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Regressor, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, 2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 2, stride=2)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 2)\n",
        "        self.conv4 = nn.Conv2d(64, 64, 2)\n",
        "                \n",
        "        self.fc1 = nn.Linear(1600, 512)\n",
        "        self.fc2 = nn.Linear(512, 512)\n",
        "        self.fc3 = nn.Linear(512, 128)\n",
        "        self.fc4 = nn.Linear(128, 128)\n",
        "        self.fc5 = nn.Linear(128, 64)\n",
        "        self.fc6 = nn.Linear(64, 32)\n",
        "        self.fc7 = nn.Linear(32, 2 + 2 + 2)\n",
        "        \n",
        "        self.dp1 = nn.Dropout(p=0.25)\n",
        "        self.dp2 = nn.Dropout(p=0.25)\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu((self.conv1(x)))\n",
        "        x = F.leaky_relu((self.conv2(x)))\n",
        "        x = F.leaky_relu((self.conv3(x)))\n",
        "        x = F.leaky_relu((self.conv4(x))) # 64, 5, 5\n",
        "        x = x.view(len(x), -1)\n",
        "\n",
        "        x = F.leaky_relu(self.fc1(x))\n",
        "        x = self.dp1(x)\n",
        "        x = F.leaky_relu(self.fc2(x))\n",
        "        x = F.leaky_relu(self.fc3(x))\n",
        "        x = self.dp2(x)\n",
        "        x = F.leaky_relu(self.fc4(x))\n",
        "        x = F.leaky_relu(self.fc5(x))\n",
        "        x = F.leaky_relu(self.fc6(x))\n",
        "        return self.fc7(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFYAS9FVDc3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regressor = Regressor().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNEjqJmNDc3b",
        "colab_type": "text"
      },
      "source": [
        "# Defining optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "YnYYpoNlDc3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 3e-4\n",
        "opt = optim.Adam(regressor.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x36DAf9rDc3c",
        "colab_type": "text"
      },
      "source": [
        "## Relative MSE that is used in competition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK4QnquLDc3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ParticleMomentum_mean, ParticlePoint_mean = ParticleMomentum.mean(dim=0), \\\n",
        "                                            ParticlePoint.mean(dim=0)\n",
        "ParticleMomentum_ParticlePoint_mean = torch.cat([ParticleMomentum_mean,\n",
        "                                                 ParticlePoint_mean]).to(device)\n",
        "\n",
        "def metric_relative_mse(y_true, y_pred):\n",
        "    return ((y_true - y_pred).pow(2).mean(dim=0) / \\\n",
        "            (y_true - ParticleMomentum_ParticlePoint_mean).pow(2).mean(dim=0)).sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79mdy7fRDc3i",
        "colab_type": "text"
      },
      "source": [
        "# Loss function\n",
        "\n",
        "In this contribution we are using `MSELoss`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVwR2_7RDc3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_fn = torch.nn.MSELoss().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXN-pf0oDc3j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RunningAverageMeter(object):\n",
        "    \"\"\"\n",
        "    Computes and stores the average and current value\n",
        "    \n",
        "    \"\"\"\n",
        "    def __init__(self, momentum=0.99):\n",
        "        self.momentum = momentum\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = None\n",
        "        self.avg = 0\n",
        "\n",
        "    def update(self, val):\n",
        "        if self.val is None:\n",
        "            self.avg = val\n",
        "        else:\n",
        "            self.avg = self.avg * self.momentum + val * (1 - self.momentum)\n",
        "        self.val = val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMnpQM06Dc3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_training(epochs=100):\n",
        "    losses = []\n",
        "    metrics = []\n",
        "    # init running average\n",
        "    loss_meter = RunningAverageMeter(momentum=0.99)\n",
        "    metric_meter = RunningAverageMeter(momentum=0.99)\n",
        "    # iterating over epochs...\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        # ...and over batches\n",
        "        for EnergyDeposit_b, ParticleMomentum_b, ParticlePoint_b, \\\n",
        "            AdditionalInfo_b in calo_dataloader:\n",
        "            # moving them to device(for example, cuda-device)\n",
        "            EnergyDeposit_b, ParticleMomentum_b, ParticlePoint_b, \\\n",
        "            AdditionalInfo_b                                     = EnergyDeposit_b.to(device), \\\n",
        "                                                                   ParticleMomentum_b.to(device), \\\n",
        "                                                                   ParticlePoint_b.to(device), \\\n",
        "                                                                   AdditionalInfo_b.to(device)\n",
        "            \n",
        "            # predicting an array of size [batch_size, 4+X]\n",
        "            pred = regressor(EnergyDeposit_b)[:,:]\n",
        "            \n",
        "\n",
        "            # calc loss function\n",
        "            loss = loss_fn(pred, torch.cat([ParticleMomentum_b, ParticlePoint_b, AdditionalInfo_b], dim=1))\n",
        "            # loss = loss_fn(pred, torch.cat([ParticleMomentum_b, ParticlePoint_b], dim=1))\n",
        "\n",
        "            # manually zeroing gradients from previous step\n",
        "            opt.zero_grad()\n",
        "            \n",
        "            # and calculating new gradients based on value of loss function\n",
        "            loss.backward()\n",
        "            \n",
        "            # updating weights\n",
        "            opt.step()\n",
        "            \n",
        "            # storing metrics for vizualization\n",
        "            loss_meter.update(loss.item())\n",
        "            metric_meter.update(metric_relative_mse(pred[:,:4], torch.cat([ParticleMomentum_b, ParticlePoint_b], dim=1)).item())\n",
        "            losses.append(loss_meter.avg)\n",
        "            metrics.append(metric_meter.avg)\n",
        "    return losses, metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "3u50F_FPDc3m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e06fe95-f5f2-444d-9a17-c3ea897d851d"
      },
      "source": [
        "# train network with 300 epochs\n",
        "losses, metrics = run_training(300)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 74%|███████▍  | 222/300 [05:01<01:46,  1.37s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKxn5LrJfTHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot loss and our metric\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.plot(losses, label='Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "        \n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.plot(metrics, label='Metric')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print(losses[-1], metrics[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC4oRjKtn0XC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save model\n",
        "torch.save(regressor, 'model.pt')\n",
        "\n",
        "# load model\n",
        "# regressor = torch.load('model.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTvqXqdaDc3n",
        "colab_type": "text"
      },
      "source": [
        "## Make predictions for validation set\n",
        "\n",
        "In `data_val.npz` and `data_test.npz` you only have one key: `EnergyDeposit`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyxjOhyKDc3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load validation data\n",
        "data_val = np.load(val_data_path, allow_pickle=True)\n",
        "EnergyDeposit_val = data_val['EnergyDeposit']\n",
        "EnergyDeposit_val = EnergyDeposit_val.reshape(-1, 1, 30, 30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSvN72UFDc3p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predicting [data_num, 4] array with px, py, x, y\n",
        "prediction_val = regressor.cpu()(torch.tensor(EnergyDeposit_val).float())[:,:4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWYB7gQ4Dc3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# splitting ParticleMomentum and ParticlePoint in two arrays\n",
        "ParticleMomentum_val, ParticlePoint_val = prediction_val.detach().numpy()[:, :2], prediction_val.detach().numpy()[:, 2:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BzfCVM2Dc3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving predictions in .npz format\n",
        "np.savez_compressed('data_val_prediction.npz', \n",
        "                    ParticlePoint=ParticlePoint_val, \n",
        "                    ParticleMomentum=ParticleMomentum_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0rb26PJDc3v",
        "colab_type": "text"
      },
      "source": [
        "## Make predictions for test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwEK2cWjDc3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loading test dataset\n",
        "data_test = np.load(test_data_path, allow_pickle=True)\n",
        "EnergyDeposit_test = data_test['EnergyDeposit']\n",
        "EnergyDeposit_test = EnergyDeposit_test.reshape(-1, 1, 30, 30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WW25RNrPDc3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predicting [data_num, 4] array with px, py, x, y\n",
        "prediction_test = regressor.cpu()(torch.tensor(EnergyDeposit_test).float())[:,:4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTDb27tnDc3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# splitting ParticleMomentum and ParticlePoint in two arrays\n",
        "ParticleMomentum_test, ParticlePoint_test = prediction_test.detach().numpy()[:, :2], prediction_test.detach().numpy()[:, 2:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DyakGLbDc3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving predictions in .npz format\n",
        "np.savez_compressed('data_test_prediction.npz', \n",
        "                    ParticlePoint=ParticlePoint_test, \n",
        "                    ParticleMomentum=ParticleMomentum_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5g7TFE2_Dc30",
        "colab_type": "text"
      },
      "source": [
        "## `zip-zip` files together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa4mMpjmDc31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip solution.zip data_val_prediction.npz data_test_prediction.npz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uc9xo4SLDc32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import FileLink\n",
        "FileLink('./solution.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgWVkv1_Dc33",
        "colab_type": "text"
      },
      "source": [
        "In Google Colab you might not be able to download you solution from browser. Then you can download it from left sidebar of Colab:\n",
        "\n",
        "![](https://github.com/philippgadow/mlhep2019_1_phase/blob/master/analysis/colab_download.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgEbIAPwDc33",
        "colab_type": "text"
      },
      "source": [
        "## Future steps:\n",
        "\n",
        "1. Tune arcitecture \n",
        "  * stack moar layers :)\n",
        "  * different types on nonlinearities, hyperparameters of `Conv2d`-layer, initializations, etc...\n",
        "  * dropout & other regularizations\n",
        "  \n",
        "  \n",
        "2. Play with optimization procedure\n",
        "  * train for more epochs\n",
        "  * maybe looking at train metricis is not the best way to prevent overfitting :)\n",
        "  * learning rate scheduler\n",
        "  * early stopping\n",
        "  * different types of loss functions: https://heartbeat.fritz.ai/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0\n",
        "  * SWA: https://pytorch.org/blog/stochastic-weight-averaging-in-pytorch/\n",
        "  \n",
        "  \n",
        "3. data augmentation\n",
        "  * rotate & shift images(do not forget to transform $p_x, p_y$, $x, y$ as well!)\n",
        "  * adding nose to images/target variables\n",
        "  \n",
        "  \n",
        "4. other trick\n",
        "  * train to predict $p_z$ and particle type: multi-task or/and transfer learning( http://rail.eecs.berkeley.edu/deeprlcourse-fa17/f17docs/lecture_15_multi_task_learning.pdf )\n",
        "  * normalization of input/output data: Box-Cox transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtywcAKXDc34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}